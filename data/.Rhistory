colnames(vulnData) <- c("test_id", "line_numbers")
vulnData$test_id <- NULL
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
source('D:/IntelliJ Projects/VulinOSS/data/AssociationExample.R')
inputData <- ("python_output\\cpython_freebsd_vuln.json")
#parse the JSON file into a data.frame
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#delete the line_range variable
results$line_range = NULL
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using results[,].
results <- results[complete.cases(results), ]
#Here line_number column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
results %>% mutate(line_number = as.factor(line_number))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
View(vulnData)
#Rename column to line_numbers
colnames(vulnData) <- c("test_id", "line_numbers")
vulnData$test_id <- NULL
#vulnData: Data to be written
#"vulnerabilities.csv": location of file with file name to be written to
#quote: If TRUE it will surround character or factor column with double quotes.
#row.names: either a logical value indicating whether the row names of x are to be
#written along with x,or a character vector of row names to be written.
write.csv(vulnData,"vulnerabilities.csv", quote = FALSE, row.names = FALSE)
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('vulnerabilities.csv', format = 'basket', sep=',')
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Line Numbers Frequency Plot")
itemFrequencyPlot(tr,topN=100,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Line Numbers Frequency Plot")
itemFrequencyPlot(tr,topN=50,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Line Numbers Frequency Plot")
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'),main="Relative Line Numbers Frequency Plot")
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('transactions.csv', format = 'basket', sep=',')
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'),main="Relative Item Frequency Plot")
# Min Support as 0.001, confidence as 0.8.
association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=10))
summary(association.rules)
#Since there are 49122 rules, print only top 10:
inspect(association.rules[1:10])
shorter.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=3))
#You can remove rules that are subsets of larger rules
subset.rules <- which(colSums(is.subset(association.rules, association.rules)) > 1) # get subset rules in vector
length(subset.rules)  #> 3913
subset.association.rules. <- association.rules[-subset.rules] # remove subset rules.
#To find what customers buy before buying 'METAL' run the following line of code:
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),appearance = list(default="lhs",rhs="METAL"))
source('D:/IntelliJ Projects/VulinOSS/data/AssociationExample.R')
# Min Support as 0.001, confidence as 0.8.
association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=10))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers")
#To find what customers buy before buying 'METAL' run the following line of code:
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),appearance = list(default="lhs",rhs="METAL"))
# Here lhs=METAL because you want to find out the probability of that in how many customers buy METAL along with other items
inspect(head(metal.association.rules))
metal.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8),appearance = list(lhs="METAL",default="rhs"))
# Here lhs=METAL because you want to find out the probability of that in how many customers buy METAL along with other items
inspect(head(metal.association.rules))
# Filter rules with confidence greater than 0.4 or 40%
subRules<-association.rules[quality(association.rules)$confidence>0.4]
#Plot SubRules
plot(subRules)
plot(subRules,method="two-key plot")
#An amazing interactive plot can be used to present your rules that use arulesViz and plotly.
#You can hover over each rule and view all quality measures (support, confidence and lift).
plotly_arules(subRules)
#select 10 rules from subRules having the highest confidence
top10subRules <- head(subRules, n = 10, by = "confidence")
#Now, plot an interactive graph
#Note: You can make all your plots interactive using engine=htmlwidget parameter in plot
plot(top10subRules, method = "graph",  engine = "htmlwidget")
#From arulesViz graphs for sets of association rules can be exported in the GraphML format or as a Graphviz dot-file to be explored
#in tools like Gephi. For example, the 1000 rules with the highest lift are exported by:
saveAsGraph(head(subRules, n = 1000, by = "lift"), file = "rules.graphml")
# Filter top 20 rules with highest lift
subRules2<-head(subRules, n=20, by="lift")
plot(subRules2, method="paracoord")
#read excel into R dataframe
retail <- read_excel('Online Retail.xlsx')
library(arules)
library(arulesViz)
library(tidyverse)
library(readxl)
library(knitr)
library(ggplot2)
library(lubridate)
library(plyr)
library(dplyr)
#read excel into R dataframe
retail <- read_excel('Online Retail.xlsx')
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using retail[,].
retail <- retail[complete.cases(retail), ]
#read excel into R dataframe
retail <- read_excel('Online Retail.xlsx')
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using retail[,].
retail <- retail[complete.cases(retail), ]
#mutate function is from dplyr package. It is used to edit or add new columns to dataframe.
#Here Description column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
retail %>% mutate(Description = as.factor(Description))
typeof(retail$Country)
retail %>% mutate(Country = as.factor(Country))
typeof(retail$Country)
#Converts character data to date. Store InvoiceDate as date in new variable
retail$Date <- as.Date(retail$InvoiceDate)
#Extract time from InvoiceDate and store in another variable
TransTime<- format(retail$InvoiceDate,"%H:%M:%S")
#Convert and edit InvoiceNo into numeric
InvoiceNo <- as.numeric(as.character(retail$InvoiceNo))
#Bind new columns TransTime and InvoiceNo into dataframe retail
cbind(retail,TransTime)
View(retail)
cbind(retail,InvoiceNo)
glimpse(retail)
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
transactionData <- ddply(retail,c("InvoiceNo","Date"),
function(df1)paste(df1$Description,
collapse = ","))
#The R function paste() concatenates vectors to character and
#separated results using collapse=[any optional character string ]. Here ',' is used
transactionData
View(transactionData)
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
transactionData <- ddply(retail,c("InvoiceNo","Date"),
function(df1)paste(df1$Description,
collapse = ","))
library(jsonlite)
library(tidyverse)
library(plyr)
library(dplyr)
inputData <- ("python_output\\cpython_freebsd_vuln.json")
#parse the JSON file into a data.frame
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#delete the line_range variable
results$line_range = NULL
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using results[,].
results <- results[complete.cases(results), ]
#Here line_number column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
results %>% mutate(line_number = as.factor(line_number))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,c("test_id","line_number"),
function(df1)paste(df1$issue_severity,
collapse = ","))
View(vulnData)
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers", "issue_severity")
#vulnData: Data to be written
#"vulnerabilities.csv": location of file with file name to be written to
#quote: If TRUE it will surround character or factor column with double quotes.
#row.names: either a logical value indicating whether the row names of x are to be
#written along with x,or a character vector of row names to be written.
write.csv(vulnData,"vulnerabilities.csv", quote = FALSE, row.names = FALSE)
TestId <- as.numeric(as.character(results$test_id))
TestId <- as.character(results$test_id)
cbind(results, TestId)
glimpse(results)
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,c("test_id","line_number"),
function(df1)paste(df1$issue_severity,
collapse = ","))
View(vulnData)
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$issue_severity,
collapse = ",",
df1$line_number,
collapse = ","))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","),
"issue_severity")
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers")
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
lineNumData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
#Rename columns to test_id and line_numbers
colnames(lineNumData) <- c("test_id", "line_numbers")
View(lineNumData)
issueSevData <- ddply(results,"test_id",
function(df1)paste(df1$issue_severity,
collapse = ","))
View(issueSevData)
inputData <- ("python_output\\glibc_vuln.json")
#parse the JSON file into a data.frame
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#delete the line_range variable
results$line_range = NULL
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using results[,].
results <- results[complete.cases(results), ]
#Here line_number column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
results %>% mutate(line_number = as.factor(line_number))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
lineNumData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","))
issueSevData <- ddply(results,"test_id",
function(df1)paste(df1$issue_severity,
collapse = ","))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
lineNumData <- ddply(results,"test_id",
function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ","))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
lineNumData <- ddply(results,"test_id",
c(function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ",")))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers", "issue_severities")
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
c(function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ",")))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers", "issue_severities")
View(vulnData)
inputData <- ("python_output\\cpython_freebsd_vuln.json")
#parse the JSON file into a data.frame
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#delete the line_range variable
results$line_range = NULL
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
c(function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ",")))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers", "issue_severities")
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('transactions.csv', format = 'basket', sep=',')
help("read.transactions")
summary(tr)
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")
if (!require("RColorBrewer")) {
# install color package of R
install.packages("RColorBrewer")
#include library RColorBrewer
library(RColorBrewer)
}
itemFrequencyPlot(tr,topN=20,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Item Frequency Plot")
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'),main="Relative Item Frequency Plot")
# Min Support as 0.001, confidence as 0.8.
association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=10))
summary(association.rules)
#Since there are 49122 rules, print only top 10:
inspect(association.rules[1:10])
retail <- read_excel('Online Retail.xlsx')
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using retail[,].
retail <- retail[complete.cases(retail), ]
#mutate function is from dplyr package. It is used to edit or add new columns to dataframe.
#Here Description column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
retail %>% mutate(Description = as.factor(Description))
retail %>% mutate(Country = as.factor(Country))
#Converts character data to date. Store InvoiceDate as date in new variable
retail$Date <- as.Date(retail$InvoiceDate)
#Extract time from InvoiceDate and store in another variable
TransTime<- format(retail$InvoiceDate,"%H:%M:%S")
#Convert InvoiceNo into numeric
InvoiceNo <- as.numeric(as.character(retail$InvoiceNo))
#Bind new columns TransTime and InvoiceNo into dataframe retail
cbind(retail,TransTime)
cbind(retail,InvoiceNo)
retail <- read_excel('Online Retail.xlsx')
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using retail[,].
retail <- retail[complete.cases(retail), ]
#mutate function is from dplyr package. It is used to edit or add new columns to dataframe.
#Here Description column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
retail %>% mutate(Description = as.factor(Description))
retail %>% mutate(Country = as.factor(Country))
#Converts character data to date. Store InvoiceDate as date in new variable
retail$Date <- as.Date(retail$InvoiceDate)
#Extract time from InvoiceDate and store in another variable
TransTime<- format(retail$InvoiceDate,"%H:%M:%S")
#Convert InvoiceNo into numeric
InvoiceNo <- as.numeric(as.character(retail$InvoiceNo))
#Bind new columns TransTime and InvoiceNo into dataframe retail
cbind(retail,TransTime)
cbind(retail,InvoiceNo)
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
transactionData <- ddply(retail,c("InvoiceNo","Date"),
function(df1)paste(df1$Description,
collapse = ","))
View(transactionData)
#set column InvoiceNo of dataframe transactionData
transactionData$InvoiceNo <- NULL
#mutate function is from dplyr package. It is used to edit or add new columns to dataframe.
#Here Description column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
retail %>% mutate(Description = as.factor(Description))
#set column Date of dataframe transactionData
transactionData$Date <- NULL
#Rename column to items
colnames(transactionData) <- c("items")
summary(tr)
#vulnData: Data to be written
#"vulnerabilities.csv": location of file with file name to be written to
#quote: If TRUE it will surround character or factor column with double quotes.
#row.names: either a logical value indicating whether the row names of x are to be
#written along with x,or a character vector of row names to be written.
write.csv(vulnData,"vulnerabilities.csv", quote = FALSE, row.names = FALSE)
nputData <- ("python_output\\cpython_freebsd_vuln.json")
#parse the JSON file into a data.frame
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#from the initial json file, you can plot issue severity against line number
#plot(as.factor(results$issue_severity), results$line_number, xlab="Issue Severity", ylab="Line Number")
#delete the line_range variable
results$line_range = NULL
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using results[,].
results <- results[complete.cases(results), ]
#(the above line might not be needed)
#Here line_number column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
results %>% mutate(line_number = as.factor(line_number))
#(the above line might not be needed)
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#from the initial json file, you can plot issue severity against line number
#plot(as.factor(results$issue_severity), results$line_number, xlab="Issue Severity", ylab="Line Number")
#delete the line_range variable
results$line_range = NULL
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using results[,].
results <- results[complete.cases(results), ]
#(the above line might not be needed)
#Here line_number column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
results %>% mutate(line_number = as.factor(line_number))
inputData <- ("python_output\\cpython_freebsd_vuln.json")
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#from the initial json file, you can plot issue severity against line number
#plot(as.factor(results$issue_severity), results$line_number, xlab="Issue Severity", ylab="Line Number")
#delete the line_range variable
results$line_range = NULL
#complete.cases(data) will return a logical vector indicating which rows have no missing values.
#Then use the vector to get only rows that are complete using results[,].
results <- results[complete.cases(results), ]
#(the above line might not be needed)
#Here line_number column is being converted to factor column. as.factor converts column to factor column
#%>% is an operator with which you may pipe values to another function or expression
results %>% mutate(line_number = as.factor(line_number))
#(the above line might not be needed)
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
c(function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ",")))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers", "issue_severities")
#vulnData: Data to be written
#"vulnerabilities.csv": location of file with file name to be written to
#quote: If TRUE it will surround character or factor column with double quotes.
#row.names: either a logical value indicating whether the row names of x are to be
#written along with x,or a character vector of row names to be written.
write.csv(vulnData,"vulnerabilities.csv", quote = FALSE, row.names = FALSE)
vulnData$test_id <- NULL
vulnData$issue_severities <- NULL
#vulnData: Data to be written
#"vulnerabilities.csv": location of file with file name to be written to
#quote: If TRUE it will surround character or factor column with double quotes.
#row.names: either a logical value indicating whether the row names of x are to be
#written along with x,or a character vector of row names to be written.
write.csv(vulnData,"vulnerabilities.csv", quote = FALSE, row.names = FALSE)
summary(tr)
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('vulnerabilities.csv', format = 'basket', sep=',')
tr
summary(tr)
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('transactions.csv', format = 'basket', sep=',')
summary(tr)
tr
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('vulnerabilities.csv', format = 'basket', sep=',')
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('transactions.csv', format = 'basket', sep=',')
#sep is how items are separated. In this case you have separated using ','
tr <- read.transactions('vulnerabilities.csv', format = 'basket', sep=',')
summary(tr)
itemFrequencyPlot(tr,topN=50,type="absolute",col=brewer.pal(8,'Pastel2'), main="Absolute Line Numbers Frequency Plot")
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'),main="Relative Line Numbers Frequency Plot")
# Min Support as 0.001, confidence as 0.8.
association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=10))
# Min Support as 0.001, confidence as 0.8.
association.rules <- apriori(tr, parameter = list(supp=0.1, conf=0.8,maxlen=10))
summary(association.rules)
inspect(association.rules[1:10])
shorter.association.rules <- apriori(tr, parameter = list(supp=0.001, conf=0.8,maxlen=3))
shorter.association.rules <- apriori(tr, parameter = list(supp=0.1, conf=0.8,maxlen=3))
#load the file
library(jsonlite)
library(tidyverse)
library(plyr)
library(dplyr)
inputData <- ("python_output\\cpython_freebsd_vuln.json")
#parse the JSON file into a data.frame
data <- jsonlite::fromJSON(inputData, simplifyDataFrame = TRUE)
#only interested in the 'results' part of the JSON file
results = data$results
#delete the line_range variable
results$line_range = NULL
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
c(function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ",")))
#Rename columns to test_id and line_numbers
colnames(vulnData) <- c("test_id", "line_numbers", "issue_severities")
vulnData <- ddply(results,c("test_id", "issue_severity"),
function(df1)paste(df1$line_number,
collapse = ","))
#ddply(dataframe, variables_to_be_used_to_split_data_frame, function_to_be_applied)
vulnData <- ddply(results,"test_id",
c(function(df1)paste(df1$line_number,
collapse = ","),
function(df1)paste(df1$issue_severity,
collapse = ",")))
vulnData <- ddply(results,c("test_id", "issue_severity"),
function(df1)paste(df1$line_number,
collapse = ","))
colnames(vulnData) <- c("test_id", "issue_severity", "line_numbers")
vulnData$test_id <- NULL
plot(vulnData)
plot(vulnData$issue_severity, vulnData$line_numbers)
plot(as.factor(vulnData$issue_severity), vulnData$line_numbers)
plot(as.factor(vulnData$issue_severity), vulnData$line_numbers, type="l")
plot(as.factor(vulnData$issue_severity), vulnData$line_numbers, type="b")
plot(as.factor(vulnData$issue_severity), vulnData$line_numbers, type="s")
typeof(vulnData$issue_severity)
typeof(vulnData$line_numbers)
plot(as.factor(vulnData$issue_severity), as.numeric(vulnData$line_numbers), type="l")
plot(as.factor(vulnData$issue_severity), as.numeric(vulnData$line_numbers), type="b")
plot(as.factor(vulnData$issue_severity), as.numeric(vulnData$line_numbers))
plot(as.factor(vulnData$issue_severity), as.numeric(unlist(vulnData$line_numbers)))
plot(as.factor(vulnData$issue_severity), unlist(vulnData$line_numbers))
line_num =
plot(as.factor(vulnData$issue_severity), unlist(vulnData$line_numbers))
line_num =
plot(as.factor(vulnData$issue_severity), as.numeric(vulnData$line_numbers))
line_num =
old_par <- plot(as.factor(vulnData$issue_severity), as.numeric(vulnData$line_numbers))
View(old_par)
source('D:/OneDrive - Brunel Account/OneDrive - Brunel University London/Uni Work/Year 3/CS3002 - Artificial Intelligence/R/Lab2.R')
line_num =
old_par <- plot(vulnData$issue_severity, as.numeric(vulnData$line_numbers))
line_num =
old_par <- plot(as.factor(vulnData$issue_severity), as.numeric(vulnData$line_numbers))
install.packages("jri")
install.packages("rJava")
install.packages("rJava")
sh configure.win
install.packages('JGR',,'http://www.rforge.net/')
sessionInfo()
install.packages('rJava',,'http://www.rforge.net/')
install.packages('rJava',,'http://www.rforge.net/')
install.packages('rJava',,'http://www.rforge.net/')
library(rJava)
